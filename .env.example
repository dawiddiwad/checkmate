# ==============================================================================
# CHECKMATE ENVIRONMENT CONFIGURATION
# ==============================================================================
# Copy this file to .env and configure with your actual values
# Never commit the .env file to version control!

# ==============================================================================
# OPENAI API CONFIGURATION (Required)
# ==============================================================================

# Your OpenAI API key (REQUIRED)
# Get your key at: https://platform.openai.com/api-keys
# Works with OpenAI, or any OpenAI-compatible provider (Claude, Gemini, etc.)
OPENAI_API_KEY=your_api_key_here

# Base URL for OpenAI-compatible API (optional)
# Override for alternative providers:
# - Anthropic Claude: https://api.anthropic.com/v1
# - Google Gemini: https://generativelanguage.googleapis.com/v1beta/openai
# - Azure OpenAI: https://YOUR_RESOURCE.openai.azure.com
# - Local LLMs: http://localhost:1234/v1
# Leave empty for standard OpenAI API
# OPENAI_BASE_URL=

# Model to use for chat-based test execution
# OpenAI models: gpt-4o, gpt-4o-mini, gpt-4-turbo, o1, o1-mini
# Claude models: claude-3-5-sonnet-latest, claude-3-5-haiku-latest
# Gemini models: gemini-2.5-flash, gemini-2.5-pro
# Default: gpt-4o-mini
OPENAI_MODEL=gpt-4o-mini

# Temperature for AI responses (0.0 to 1.0)
# 0.1 = deterministic/predictable, 1 = creative/varied
# Recommended: range from 0.1 to 0.3 for consistent behavior
OPENAI_TEMPERATURE=0.1

# Tool choice mode for function calling
# Options: auto, required, none
# Default: required (forces tool use for each response)
# OPENAI_TOOL_CHOICE=required

# API request timeout in seconds
# Default: 60
# OPENAI_TIMEOUT_SECONDS=60

# Maximum retry attempts for failed API requests
# Default: 3
# OPENAI_RETRY_MAX_ATTEMPTS=3

# Include screenshot in snapshot responses
# When enabled, screenshots are sent using OpenAI's vision API format (detail: low)
# This uses only 85 tokens per screenshot regardless of image size
# Screenshots are sent as separate user messages after tool responses
# Options: true, false
# Default: false (screenshots disabled)
# OPENAI_INCLUDE_SCREENSHOT_IN_SNAPSHOT=false

# Enable snapshot compression
# When enabled, accessibility tree snapshots are compressed using abbreviated element notation
# This significantly reduces token usage (~40% reduction) but may reduce context clarity
# Options: true, false
# Default: true (compression enabled)
# OPENAI_ENABLE_SNAPSHOT_COMPRESSION=true

# Rate limit delay (seconds between API calls)
# Use if experiencing rate limiting from your provider
# OPENAI_API_RATE_LIMIT_DELAY_SECONDS=1

# ==============================================================================
# PLAYWRIGHT MCP SERVER CONFIGURATION (Optional)
# ==============================================================================

# Playwright MCP package version
# Default: latest
# Example: 0.4.7 (pin to specific version for stability)
# PLAYWRIGHT_MCP_VERSION=latest

# Browser to use for test execution
# Options: chromium, firefox, webkit
# Default: chromium
# PLAYWRIGHT_MCP_BROWSER=chromium

# Run browser in headless mode (no visible browser window)
# Options: true, false
# Default: false (headed mode for debugging)
# Recommended: true for CI/CD environments
# PLAYWRIGHT_MCP_HEADLESS=false

# Directory for test artifacts (screenshots, videos, traces)
# Default: ./test-results
# PLAYWRIGHT_MCP_OUTPUT_DIR=./test-results

# Viewport size for browser window
# Format: WIDTHxHEIGHT (e.g., 1280x720)
# PLAYWRIGHT_MCP_VIEWPORT_SIZE=1280x720

# Record video of test execution
# Format: WIDTHxHEIGHT (e.g., 1280x720)
# Leave empty to disable video recording
# Warning: Videos significantly increase storage and costs
# PLAYWRIGHT_MCP_SAVE_VIDEO_SIZE=1280x720

# Use isolated browser contexts for each test
# Options: true, false
# Default: false
# When enabled, each test gets a fresh browser context (no shared state)
# PLAYWRIGHT_MCP_ISOLATED=false

# Custom browser capabilities (use with care, impact on token usage and response times)
# Example: vision, testing
# PLAYWRIGHT_MCP_CAPS=vision,testing

# ==============================================================================
# PLAYWRIGHT TEST RUNNER CONFIGURATION (Optional)
# ==============================================================================

# CI/CD mode indicator
# Set to any value to enable CI optimizations:
# - Uses 100% of available workers (faster execution)
# - Disables output directory override
# - Optimizes resource usage
# Leave empty for local development
# CI=true

# ==============================================================================
# SALESFORCE CONFIGURATION (Optional - Required for Salesforce tests only)
# ==============================================================================

# No environment variables needed!
# Salesforce integration uses the Salesforce CLI (sf) with default org.
# 
# Prerequisites:
#   1. Install Salesforce CLI: npm install -g @salesforce/cli
#   2. Authenticate to your org: sf org login web --alias my-org
#   3. Set default org: sf config set target-org my-org
#
# The framework will automatically use your authenticated org.

# ==============================================================================
# GEMINI LIVE API CONFIGURATION (Experimental)
# ==============================================================================
# For experimental Gemini Live API tests (npm run test:live)
# These tests use Google's real-time streaming API for faster responses

# Google API key for Gemini Live API
# Get your key at: https://aistudio.google.com/app/apikey
# GOOGLE_API_KEY=your_gemini_api_key_here

# Temperature for Live API (same as OPENAI_TEMPERATURE)
# GOOGLE_API_TEMPERATURE=0.1

# Include screenshot in snapshot responses for Live API
# GOOGLE_API_INCLUDE_SCREENSHOT_IN_SNAPSHOT=false

# ==============================================================================
# DEVELOPMENT & DEBUGGING (Optional)
# ==============================================================================

# Enable debug mode for MCP communication (adds verbose logging)
# DEBUG=true

# Node environment
# Options: development, production, test
# NODE_ENV=development

# ==============================================================================
# COST OPTIMIZATION TIPS
# ==============================================================================
#
# 1. Use gpt-4o-mini for lower costs (~15x cheaper than gpt-4o)
# 2. Keep OPENAI_TEMPERATURE at 0.1 for consistent, predictable results
# 3. Disable video recording unless specifically needed
# 4. Use headless mode in CI/CD to reduce resource usage
# 5. Set PLAYWRIGHT_MCP_ISOLATED=false to share browser contexts
#
# Estimated costs (GPT-4o-mini):
# - Simple test (5 steps): $0.01 - $0.05
# - Complex flow (20 steps): $0.10 - $0.40
# - Full test suite (50 tests): $5.00 - $20.00
#
# Model pricing comparison (per 1M tokens):
# - gpt-4o-mini: $0.15 input / $0.60 output
# - gpt-4o: $2.50 input / $10.00 output
# - claude-3-5-sonnet: $3.00 input / $15.00 output
# - gemini-2.5-flash: $0.30 input / $1.25 output

# ==============================================================================
# NOTES
# ==============================================================================
#
# - All paths are relative to the project root unless absolute paths provided
# - Screenshot compression is automatic (768x768) to reduce token costs
# - Chat history filtering removes snapshots to prevent context bloat
# - Token usage is logged after each step for cost tracking
# - Each test step gets a fresh session to prevent context overflow
#
# For more information, see README.md
