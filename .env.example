# ==============================================================================
# CHECKMATE ENVIRONMENT CONFIGURATION
# ==============================================================================
# Copy this file to .env and configure with your actual values
# Never commit the .env file to version control!

# ==============================================================================
# OPENAI API CONFIGURATION (Required)
# ==============================================================================

# Example configuration for Google Gemini (recommended for cost efficiency)

# Get a free Gemini API key from https://aistudio.google.com/app/api-keys
OPENAI_API_KEY=your_api_key_here

# Google Gemini Base URL for OpenAI-compatible API
OPENAI_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/

# Model configuration
OPENAI_MODEL=gemini-2.5-flash
OPENAI_TEMPERATURE=0

# Your OpenAI API key (REQUIRED)
# Get your key at: https://platform.openai.com/api-keys
# Works with OpenAI, or any OpenAI-compatible provider (Claude, Gemini, etc.)
# OPENAI_API_KEY=your_api_key_here

# Base URL for OpenAI-compatible API (optional)
# Override for alternative providers:
# - Anthropic Claude: https://api.anthropic.com/v1
# - Google Gemini: https://generativelanguage.googleapis.com/v1beta/openai
# - Azure OpenAI: https://YOUR_RESOURCE.openai.azure.com
# - Local LLMs: http://localhost:1234/v1
# Leave empty for standard OpenAI API
# OPENAI_BASE_URL=

# Model to use for chat-based test execution 
# NOTE: these are just examples, you can use pretty much any model
# OpenAI: gpt-4.1-mini, gpt-5-mini, gpt-5.1, gpt-5.2, gpt-5-nano
# Gemini: gemini-2.5-flash, gemini-2.5-pro
# Claude: claude-4-5-sonnet-latest, claude-4-5-haiku
# Default: gpt-4.1-mini
# OPENAI_MODEL=gpt-4.1-mini

# Temperature for AI responses (0.0 to 1.0)
# NOTE: some models (like gpt-5-mini) may not support temperature settings
# 0.1 = deterministic/predictable, 1 = creative/varied
# Recommended: range from 0.1 to 0.3 for consistent behavior
# OPENAI_TEMPERATURE=0.1

# Reasoning effort for models
# Controls the amount of reasoning effort for models that support extended thinking
# Options: low, medium, high
# Only applicable to reasoning models (mianly openai gpt models, but might work with others)
# Leave empty or unset for non-reasoning models
# OPENAI_REASONING_EFFORT=high

# Tool choice mode for function calling
# Options: auto, required, none
# Default: required (forces tool use for each response)
# OPENAI_TOOL_CHOICE=required

# API request timeout in seconds
# Default: 60
# OPENAI_TIMEOUT_SECONDS=60

# Maximum retry attempts for failed API requests
# Retries on: 408 (timeout), 409 (conflict), 429 (rate limit), 5xx (server errors)
# Uses progressive backoff: 1s, 10s, 60s that respects Retry-After headers
# Default: 3
# OPENAI_RETRY_MAX_ATTEMPTS=3

# Include screenshot in snapshot responses
# When enabled, screenshots are sent using OpenAI's vision API format (detail: low)
# This uses only 85 tokens per screenshot regardless of image size
# Screenshots are sent as separate user messages after tool responses
# Options: true, false
# Default: false (screenshots disabled)
# OPENAI_INCLUDE_SCREENSHOT_IN_SNAPSHOT=false

# ------------------------------
# Token budget / cost control (optional)
# ------------------------------
# Set a USD budget (decimal) for total cost across a single test run. Only positive values are enforced.
# Example: OPENAI_API_TOKEN_BUDGET_USD=10.50
# If unset or invalid, no USD budget enforcement is applied.
# OPENAI_API_TOKEN_BUDGET_USD=

# Set a token count budget (integer) to limit the total tokens consumed across a single test run.
# Example: OPENAI_API_TOKEN_BUDGET_COUNT=100000
# If unset or invalid, no token count budget enforcement is applied.
# OPENAI_API_TOKEN_BUDGET_COUNT=

# ------------------------------
# Loop detection / recovery
# ------------------------------
# Maximum number of repetitive tool call patterns before triggering loop recovery.
# When a loop is detected, the framework adjusts temperature randomly to break out of the loop.
# Default: 5
# OPENAI_LOOP_MAX_REPETITIONS=5

# Allowed tools (comma-separated list)
# Restricts which tools the model can use. If not set, all tools are available.
# Available browser tools:
#   Core: browser_click, browser_close, browser_console_messages, browser_drag, browser_evaluate,
#         browser_file_upload, browser_fill_form, browser_handle_dialog, browser_hover, browser_navigate,
#         browser_navigate_back, browser_network_requests, browser_press_key, browser_resize,
#         browser_run_code, browser_select_option, browser_snapshot, browser_take_screenshot,
#         browser_type, browser_wait_for, browser_tabs, browser_install
#   Vision (--caps=vision): browser_mouse_click_xy, browser_mouse_drag_xy, browser_mouse_move_xy
#   PDF (--caps=pdf): browser_pdf_save
#   Testing (--caps=testing): browser_generate_locator, browser_verify_element_visible,
#                             browser_verify_list_visible, browser_verify_text_visible, browser_verify_value
#   Tracing (--caps=tracing): browser_start_tracing, browser_stop_tracing
# Step tools: pass_test_step, fail_test_step
# Salesforce tools: login_to_salesforce_org
# Example: OPENAI_ALLOWED_TOOLS=browser_click,browser_navigate,browser_type,browser_snapshot,pass_test_step,fail_test_step
# OPENAI_ALLOWED_TOOLS=

# Rate limit delay (seconds between API calls)
# Use if experiencing rate limiting from your provider
# OPENAI_API_RATE_LIMIT_DELAY_SECONDS=1

# ==============================================================================
# LOGGING CONFIGURATION
# ==============================================================================

# Log level for Checkmate operations
# Controls the verbosity of logs for test execution, tool calls, and API interactions
# Uses Winston logger with structured JSON output for better readability
# Options: debug, info, warn, error, off
# Default: off (no logging)
# Recommended: info for general usage, debug for troubleshooting
# CHECKMATE_LOG_LEVEL=off

# ==============================================================================
# SNAPSHOT CONFIGURATION
# ==============================================================================

# Enable fuzzy-search snapshot filtering
# When enabled and search keywords are provided in test steps, page snapshots are filtered
# to include only elements relevant to those keywords
# Uses local fuzzy keyword matching (Dice coefficient) to identify relevant UI elements
# NOTE: Search keywords must be provided by the user at the step level (no LLM extraction)
# You can use your IDE's AI model or autocomplete to generate these keywords
# from your action/expect descriptions, though manual review may be needed for optimal performance
# Reduces token usage by up to 90% for complex pages when optimal keywords are provided
# Options: true, false
# Default: true (filtering enabled when keywords are provided)
# Set to false to disable filtering and send full page snapshots to the LLM
# CHECKMATE_SNAPSHOT_FILTERING=true

# ==============================================================================
# BROWSER CONFIGURATION
# ==============================================================================

# Browser settings (viewport, headless mode, video, timeouts, etc.) are configured
# in playwright.config.ts using Playwright's standard configuration mechanism.
# See: https://playwright.dev/docs/test-configuration

# ==============================================================================
# PLAYWRIGHT TEST RUNNER CONFIGURATION
# ==============================================================================
# Most Playwright settings are configured in playwright.config.ts
# See: https://playwright.dev/docs/test-configuration

# CI/CD mode indicator
# Set to any value to enable CI optimizations
# Leave empty for local development
# CI=

# ==============================================================================
# SALESFORCE CONFIGURATION (Optional - Required for Salesforce tests only)
# ==============================================================================

# No environment variables needed!
# Salesforce integration uses the Salesforce CLI (sf) with default org.
# The login_to_salesforce_org tool handles complete authentication:
# - Retrieves front-door URL from SF CLI session
# - Automatically navigates browser to login
# 
# Prerequisites:
#   1. Install Salesforce CLI: npm install -g @salesforce/cli
#   2. Authenticate to your org: sf org login web --alias my-org --set-default
#   3. The framework will automatically use your authenticated org.
#
# In tests, simply use: await ai.run({ action: 'Login to Salesforce org', expect: '...' })

# ==============================================================================
# COST OPTIMIZATION TIPS
# ==============================================================================
#
# 1. Use gemini-2.5-flash or gpt-5-mini for lower costs
# 2. Keep OPENAI_TEMPERATURE at 0 for consistent, deterministic results
# 3. Keep OPENAI_INCLUDE_SCREENSHOT_IN_SNAPSHOT=false (only 85 tokens when needed)
# 4. Set token budgets to prevent runaway costs
# 5. Disable video recording unless debugging specific issues
#
# Estimated costs (Gemini 2.5 Flash):
# - Simple test (5 steps): $0.01 - $0.03
# - Complex flow (20 steps): $0.10 - $0.30
# - Full test suite (50 tests): $3.00 - $10.00
#
# Model pricing comparison (per 1M tokens):
# - gemini-2.5-flash: $0.30 input / $1.25 output (recommended)
# - gpt-5-mini: $0.25 input / $2.00 output
# - claude-4-5-sonnet: $3.00 input / $15.00 output

# ==============================================================================
# NOTES
# ==============================================================================
#
# - Browser configuration (viewport, timeouts, video, etc.) is in playwright.config.ts
# - Screenshot compression is automatic (768x768) to reduce token costs
# - Snapshot minification automatically removes unnecessary whitespace and quotes
# - Chat history filtering removes old snapshots to prevent context bloat
# - Token usage is logged after each step for cost tracking
# - Loop detection prevents infinite loops with automatic temperature adjustment
# - Each test step gets a fresh AI session to prevent context overflow
#
# For more information, see README.md
